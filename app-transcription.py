# app-transcription.py
import os
import io
import time
from pathlib import Path
from datetime import timedelta

import streamlit as st
from openai import OpenAI
from openai import APIConnectionError, RateLimitError, APITimeoutError, BadRequestError, APIStatusError

# ---------------------- Config UI ----------------------
st.set_page_config(page_title="Transcription (Whisper) ‚Äî Sans FFmpeg", layout="centered")
st.title("üéôÔ∏è Transcription audio/vid√©o (OpenAI Whisper) ‚Äî mode sans FFmpeg")

API_KEY = st.secrets.get("OPENAI_API_KEY", "")
if not API_KEY:
    st.error(
        "Aucune cl√© OpenAI d√©tect√©e. Ajoutez-la dans `.streamlit/secrets.toml` (local) "
        "ou dans **Manage app ‚Üí Settings ‚Üí Secrets** sur streamlit.app :\n\n"
        "```\nOPENAI_API_KEY = \"sk-...\"\n```"
    )
    st.stop()

SUPPORTED_EXT = [".mp3", ".mp4", ".wav", ".m4a"]  # pas de conversion/d√©coupage c√¥t√© serveur

# ---------------------- Utils ----------------------
def fmt_bytes(num: int) -> str:
    for unit in ["B", "KB", "MB", "GB"]:
        if num < 1024.0:
            return f"{num:.2f} {unit}"
        num /= 1024.0
    return f"{num:.2f} TB"

def fmt_time_ms(ms: float) -> str:
    return str(timedelta(milliseconds=int(ms)))

def safe_name(name: str) -> str:
    try:
        return name.encode("utf-8", "ignore").decode("utf-8")
    except Exception:
        return "fichier"

# Buffer de logs
if "log_text" not in st.session_state:
    st.session_state["log_text"] = ""

# Un seul placeholder pour les logs (pas de widget √† √©tat)
log_placeholder = st.empty()

def append_log(msg: str):
    """Ajoute une ligne au journal d'ex√©cution et rafra√Æchit l'affichage."""
    st.session_state["log_text"] += (("\n" if st.session_state["log_text"] else "") + msg)
    # Affichage via st.code: pas de gestion d'√©tat de widget, pas d'ID dupliqu√©s
    log_placeholder.code(st.session_state["log_text"], language="text")

# ---------------------- UI param√®tres ----------------------
with st.expander("‚öôÔ∏è Param√®tres", expanded=True):
    language = st.selectbox("Langue √† forcer (meilleure pr√©cision)", ["fr", "en", "es", "de", "it"], index=0)
    request_timeout = st.slider("Timeout requ√™te (secondes)", min_value=30, max_value=300, value=90, step=10)
    verbose_debug = st.toggle("Mode verbeux (debug)", value=False, help="Affiche la trace compl√®te des erreurs")

uploaded = st.file_uploader(
    "D√©posez un fichier audio/vid√©o (mp3, mp4, wav, m4a) ‚Äî 200 Mo max sur streamlit.app",
    type=[ext[1:] for ext in SUPPORTED_EXT]
)

# Affiche le journal initial (vide ou existant)
log_placeholder.code(st.session_state["log_text"] or "Journal d‚Äôex√©cution‚Ä¶", language="text")

# ---------------------- Action ----------------------
if uploaded is not None:
    fname = safe_name(uploaded.name)
    fsize = len(uploaded.getbuffer())
    fext = Path(fname).suffix.lower()

    st.write(f"**Fichier** : `{fname}` ‚Äî **Taille** : {fmt_bytes(fsize)}")
    if fext not in SUPPORTED_EXT:
        st.error(f"Format non support√© : {fext}. Formats accept√©s : {', '.join(SUPPORTED_EXT)}")
        st.stop()

    if st.button("üöÄ Lancer la transcription", type="primary"):
        client = OpenAI(api_key=API_KEY, timeout=request_timeout)  # timeout global

        start_ts = time.time()
        append_log("D√©marrage de la transcription (mode direct, sans conversion ni d√©coupage)‚Ä¶")

        # On lit en BytesIO pour passer un file-like au client
        file_like = io.BytesIO(uploaded.getbuffer())
        file_like.name = fname  # utile pour l'API c√¥t√© serveur

        with st.status("Transcription en cours‚Ä¶", expanded=True) as status:
            try:
                st.write("‚û°Ô∏è Envoi du fichier √† Whisper (appel API)‚Ä¶")
                t0 = time.time()
                resp = client.audio.transcriptions.create(
                    model="whisper-1",
                    file=file_like,
                    language=language,
                    # prompt=None,
                    # temperature=0,
                )
                t_api = time.time() - t0
                append_log(f"Appel API termin√© en {t_api:.1f}s.")

                text = getattr(resp, "text", "").strip() if resp else ""
                if not text:
                    append_log("‚ö†Ô∏è Whisper a renvoy√© une r√©ponse vide.")
                    st.warning("Aucun texte renvoy√© par le mod√®le.")
                else:
                    append_log(f"‚úÖ Transcription re√ßue ({len(text)} caract√®res).")

                status.update(label="Fini", state="complete")

            except (APITimeoutError, APIConnectionError) as net_err:
                append_log("‚ùå Erreur de r√©seau / timeout avec l‚ÄôAPI OpenAI.")
                if verbose_debug:
                    st.exception(net_err)
                else:
                    st.error(f"Erreur r√©seau/timeout : {net_err}")
                text = ""
            except RateLimitError as rle:
                append_log("‚ùå Rate limit atteint (trop de requ√™tes).")
                if verbose_debug:
                    st.exception(rle)
                else:
                    st.error("Rate limit atteint. R√©essaie dans quelques instants.")
                text = ""
            except BadRequestError as bre:
                append_log("‚ùå Requ√™te invalide (BadRequestError) ‚Äî souvent un probl√®me de taille/format.")
                if verbose_debug:
                    st.exception(bre)
                else:
                    st.error(f"BadRequest : {bre}")
                text = ""
            except APIStatusError as ase:
                append_log(f"‚ùå Erreur serveur OpenAI (status {ase.status_code}).")
                if verbose_debug:
                    st.exception(ase)
                else:
                    st.error(f"Erreur OpenAI : status {ase.status_code}")
                text = ""
            except Exception as e:
                append_log("‚ùå Exception non g√©r√©e pendant la transcription.")
                if verbose_debug:
                    st.exception(e)
                else:
                    st.error(f"Erreur : {e}")
                text = ""

        total_s = time.time() - start_ts
        append_log(f"Dur√©e totale du traitement : {fmt_time_ms(total_s * 1000)}")

        st.subheader("üìù R√©sultat")
        if text:
            st.text_area("Transcription (aper√ßu)", value=text, height=300, key="result_area", disabled=False)
            out_name = f"{Path(fname).stem}.txt"
            st.download_button("üíæ T√©l√©charger le .txt", data=text.encode("utf-8"), file_name=out_name, mime="text/plain")
        else:
            st.info(
                "Pas de transcription.\n\n"
                "üí° Pistes sans FFmpeg :\n"
                "- R√©duire la taille/dur√©e du fichier (couper localement en parties < 20‚Äì30 min).\n"
                "- Essayer un format **WAV mono 16 kHz** (si ton outil d‚Äôenregistrement le permet).\n"
                "- Ex√©cuter l‚Äôapplication **en local** (aucune limite d‚Äôupload Streamlit Cloud) puis pousser le .txt."
            )
